{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks and Robustness ï½œ FGSM\n",
    "\n",
    "This tutorial demonstrates how to use the **fast gradient sign method  (FSGM)** [1] to generate adversarial examples for handwritten digit classification on the [MNIST](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) dataset. \n",
    "\n",
    "<!-- Use this command to show the figure if you are offline. -->\n",
    "<!-- <img src=\"Util/demo2_1.jpg\" alt=\"white-box attack\" width=\"500\"/> -->\n",
    "\n",
    "<img src=\"https://github.com/siyi-wind/TAIMI_trustworthy/raw/main/Util/demo2_1.jpg\" alt=\"Alt text\" width=\"500\">\n",
    "\n",
    "In this tutorial, we will cover the following topics\n",
    "\n",
    "- Prepare the dataset and model\n",
    "\n",
    "- Train the model\n",
    "\n",
    "- FSGM\n",
    "\n",
    "    - Define FSGM\n",
    "\n",
    "    - Generate adversarial examples through FSGM\n",
    "    \n",
    "    - Evaluate the attack performance\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note**: To use Google Colab's GPU, click 'Runtime' --> 'Change runtime type' -->  'T4 GPU'\n",
    "\n",
    "The tutorial is based on [this repository](https://github.com/trustworthy-ml-course/trustworthy-ml-course.github.io/blob/main/demos/Demo-2.ipynb).\n",
    "\n",
    "[1] Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining and harnessing adversarial examples.\" ICLR 2015.\n",
    "[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: If you use Google Colab, uncomment the following code\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# # Change to the path of the tutorial\n",
    "# import os\n",
    "# path = './gdrive/MyDrive/Code/ic/TAIMI_trustworthy' \n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='Data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='Data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = DNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model\n",
    "\n",
    "Define the loss function and optimizer, and train the model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model before attacking\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0  # Initialize the number of correct predictions and the total number of images\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define the FGSM Attack\n",
    "\n",
    "The FGSM attack perturbs input in the direction of the sign of the gradient of the loss w.r.t. the input, scaled by a perturbation budget.\n",
    "\n",
    "<!-- Use this command to show the figure if you are offline. -->\n",
    "<!-- <img src=\"Util/demo2_2.jpg\" alt=\"FGSM\" width=\"600\"/> -->\n",
    "\n",
    "<img src=\"https://github.com/siyi-wind/TAIMI_trustworthy/raw/main/Util/demo2_2.jpg\" alt=\"Alt text\" width=\"600\">\n",
    "\n",
    "Here $\\epsilon$ represents the magnitude of the perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_attack(model, image, label, epsilon):\n",
    "\n",
    "    image.requires_grad = True # since we're acting on the image\n",
    "    model.zero_grad()\n",
    "\n",
    "    output = model(image)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "\n",
    "    _, init_pred = torch.max(output.detach(), 1)\n",
    "\n",
    "    # TODO: Implement the FGSM attack\n",
    "    perturbed_image = 0.0\n",
    "\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1) # clip to ensure pixel values stay in the normalized [0,1] range\n",
    "    return init_pred, perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate FGSM Attack\n",
    "\n",
    "Test the model on adversarial examples generated using FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FGSM(model, device, test_loader, epsilon):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_examples = []   \n",
    "\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        init_pred, x_adv = FGSM_attack(model,x,y,epsilon)\n",
    "\n",
    "        output = model(x_adv)\n",
    "        _, final_pred = torch.max(output, 1)\n",
    "\n",
    "        correct += (final_pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        # save a few adversarial examples for visualization. Only save the samples where the model has correctly classified the original image \n",
    "        if init_pred.item() == y.item() and len(adv_examples) < 10:\n",
    "            adv_ex = x_adv.squeeze().detach().cpu().numpy()\n",
    "            adv_examples.append((y.cpu(), init_pred.item(), final_pred.item(), x.squeeze().detach().cpu().numpy(), adv_ex))\n",
    "    \n",
    "    final_acc = correct / total\n",
    "    print('Done running FGSM on', total, f'test samples, with epsilon = {epsilon:.2f}', f'| Accuracy: {final_acc:.4f}')\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different epsilon values. epsilon = 0.00 is the model's accuracy without any attack\n",
    "epsilons = [0.00, 0.05, 0.10, 0.15, 0.20]\n",
    "accuracies = []\n",
    "examples = []\n",
    "test_dataloader_FGSM = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = test_FGSM(model, device, test_dataloader_FGSM, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Visualize Results\n",
    "\n",
    "Visualize the accuracy drop and the adversarial examples w.r.t different epsilon values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs epsilon\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row shows several adversarial sample for a given epsilon value\n",
    "fig, axes = plt.subplots(nrows=len(epsilons), ncols=len(examples[0]), figsize=(3*len(epsilons), 9))\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[0])):\n",
    "        axes[i, j].imshow(examples[i][j][4].squeeze(), cmap='gray')\n",
    "        axes[i, j].set_title(f\"{examples[i][j][1]} -> {examples[i][j][2]}\")\n",
    "        if j == 0:\n",
    "            axes[i, 0].set_ylabel(f\"Epsilon: {epsilons[i]}\")\n",
    "        else:\n",
    "            axes[i, j].set_ylabel(\"\")\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking\n",
    "\n",
    "1. How do you choose the value of $\\epsilon$ in FGSM, and how does it affect the success of the attack?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustworthy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
