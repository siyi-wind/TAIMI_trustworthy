{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness and Privacy\n",
    "This demo demonstrates how to mitigate unfairness through resampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# seed everything\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you use Colab\n",
    "# # TODO\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# # Path to the directory containing the data\n",
    "# import os\n",
    "# path = './gdrive/MyDrive/Code/ic/TAIMI_trustworthy' \n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare the Skin Lesion Dataset\n",
    "Here we use a small split of the ISIC 2019 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_code</th>\n",
       "      <th>sex</th>\n",
       "      <th>sex_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0034321</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0034322</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0034324</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0034325</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0034328</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ISIC_0054574</td>\n",
       "      <td>MEL</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ISIC_0054577</td>\n",
       "      <td>MEL</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ISIC_0054612</td>\n",
       "      <td>MEL</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ISIC_0054637</td>\n",
       "      <td>MEL</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ISIC_0054645</td>\n",
       "      <td>MEL</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image label  label_code     sex  sex_code\n",
       "0    ISIC_0034321    NV           0  female         0\n",
       "1    ISIC_0034322    NV           0    male         1\n",
       "2    ISIC_0034324    NV           0    male         1\n",
       "3    ISIC_0034325    NV           0  female         0\n",
       "4    ISIC_0034328    NV           0    male         1\n",
       "..            ...   ...         ...     ...       ...\n",
       "495  ISIC_0054574   MEL           1  female         0\n",
       "496  ISIC_0054577   MEL           1    male         1\n",
       "497  ISIC_0054612   MEL           1    male         1\n",
       "498  ISIC_0054637   MEL           1  female         0\n",
       "499  ISIC_0054645   MEL           1  female         0\n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the data distribution\n",
    "df = pd.read_csv('Data/ISIC2019/label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NV     250\n",
       "MEL    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label distribution\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      268\n",
       "female    232\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitive attribute (sex) distribution\n",
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 400\n",
      "Number of samples: 100\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/siyi/project/course/TAIMI_trustworthy/Data/ISIC2019/images'\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None, do_train=False):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.do_train = do_train\n",
    "        if self.do_train:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        print(f'Number of samples: {len(self.df)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['image']\n",
    "        img_path = self.root_dir + '/' + img_name + '.jpg'\n",
    "        image = Image.open(img_path)\n",
    "        label = row['label_code']\n",
    "        sensitive_attr = row['sex_code']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, sensitive_attr, img_name\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(size=224), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create train and test datasets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=2025)\n",
    "train_dataset = ISICDataset(train_df, root_dir, transform=train_transform, do_train=True)\n",
    "test_dataset = ISICDataset(test_df, root_dir)\n",
    "\n",
    "# Create train and test dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, len(df['label'].unique()))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model\n",
    "Define the loss function and optimizer, and train the model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def training(model, criterion, optimizer, train_loader, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels, _, _ in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    return model\n",
    "\n",
    "\n",
    "def testing(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        prediction_list = []\n",
    "        label_list = []\n",
    "        s_list = []\n",
    "        prob_list = []  # Save True class probability for AUC calculation\n",
    "        for images, labels, s, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            probs = F.softmax(outputs.detach(), dim=1)\n",
    "            probs = probs[:, 1]  # Probability of True class\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Save predictions, labels, and sensitive attributes\n",
    "            prediction_list.extend(predicted.cpu().numpy())\n",
    "            label_list.extend(labels.cpu().numpy())\n",
    "            s_list.extend(s.cpu().numpy())\n",
    "            prob_list.extend(probs.cpu().numpy())\n",
    "        \n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    return prediction_list, prob_list, label_list, s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2950\n",
      "Epoch [2/10], Loss: 0.4005\n",
      "Epoch [3/10], Loss: 0.0306\n",
      "Epoch [4/10], Loss: 0.5105\n",
      "Epoch [5/10], Loss: 0.1221\n",
      "Epoch [6/10], Loss: 0.0373\n",
      "Epoch [7/10], Loss: 0.2420\n",
      "Epoch [8/10], Loss: 0.0261\n",
      "Epoch [9/10], Loss: 0.1458\n",
      "Epoch [10/10], Loss: 0.1415\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Train the model\n",
    "model = training(model, criterion, optimizer, train_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "# Test and save the model\n",
    "predictions, probs, labels, sensitive_attrs = testing(model, test_loader)\n",
    "torch.save(model.state_dict(), 'Checkpoint/ISIC2019_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate Evaluation Metrics\n",
    "#### Classification Performance\n",
    "* Accuracy\n",
    "* Area under the curve (AUC)\n",
    "\n",
    "\n",
    "#### Fairness Metrics\n",
    "* Demographic Parity: The predicted positive rate should be equal across sensitive attributes ($s \\in S$).\n",
    "$$\n",
    "DP = \\operatorname{abs}[p(\\hat{y}=1|s=0)-p(\\hat{y}=1|s=1)]\n",
    "$$\n",
    "\n",
    "* Accuracy Parity: The accuracy should be equal across sensitive attributes.\n",
    "$$\n",
    "AP = \\operatorname{abs}[p(\\hat{y}=y|s=0)-p(\\hat{y}=y|s=1)]\n",
    "$$\n",
    "\n",
    "* Equalized Odds: The true positive rates (TPRs) and false positive rates (FPRs) should be equalized across sensitive attributes.\n",
    "$$\n",
    "EOD = \\operatorname{abs}[p(\\hat{y}=1|\\hat{y}=y, s=0)-p(\\hat{y}=1|\\hat{y}=y, s=1)]\n",
    "$$\n",
    "\n",
    "* Equal Opportunity: The the true positive rates should be equalized across sensitive attributes.\n",
    "$$\n",
    "EO = \\operatorname{abs}[p(\\hat{y}=1|\\hat{y}=1, s=j)-p(\\hat{y}=1|\\hat{y}=1, s=j)]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.89\n",
      "AUC: 0.9684\n"
     ]
    }
   ],
   "source": [
    "# Classification performance\n",
    "auc = roc_auc_score(labels, probs)\n",
    "accuracy = np.mean(np.array(predictions) == np.array(labels))\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "print(f'AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity: 0.1597\n",
      "Accuracy Parity: 0.1044\n",
      "Equalized Odds: 0.1235\n",
      "Equal Opportunity: 0.2174\n"
     ]
    }
   ],
   "source": [
    "# Fairness performance\n",
    "g0_idx = np.where(np.array(sensitive_attrs) == 0)[0]\n",
    "g1_idx = np.where(np.array(sensitive_attrs) == 1)[0]\n",
    "\n",
    "g0_pred = np.array(predictions)[g0_idx]\n",
    "g1_pred = np.array(predictions)[g1_idx]\n",
    "\n",
    "g0_labels = np.array(labels)[g0_idx]\n",
    "g1_labels = np.array(labels)[g1_idx]\n",
    "\n",
    "# Demographic Parity\n",
    "def demographic_parity(g0_pred, g1_pred):\n",
    "    dp = np.abs(np.mean(g0_pred==1) - np.mean(g1_pred==1))\n",
    "    return dp\n",
    "\n",
    "# Accuracy Parity\n",
    "def accuracy_parity(g0_pred, g1_pred, g0_labels, g1_labels):\n",
    "    g0_acc = np.mean(g0_pred==g0_labels)\n",
    "    g1_acc = np.mean(g1_pred==g1_labels)\n",
    "    ap = np.abs(g0_acc - g1_acc)\n",
    "    return ap\n",
    "\n",
    "# Equalized Odds\n",
    "def equalized_odds(g0_pred, g1_pred, g0_labels, g1_labels):\n",
    "    if np.sum(g0_pred==g0_labels) == 0:\n",
    "        g0_rate = 0\n",
    "    else:\n",
    "        g0_rate = np.sum((g0_pred==1) & (g0_labels==1)) / np.sum(g0_pred==g0_labels)\n",
    "    if np.sum(g1_pred==g1_labels) == 0:\n",
    "        g1_rate = 0\n",
    "    else:\n",
    "        g1_rate = np.sum((g1_pred==1) & (g1_labels==1)) / np.sum(g1_pred==g1_labels)\n",
    "    eod = np.abs(g0_rate - g1_rate)\n",
    "    return eod\n",
    "\n",
    "# Equal Opportunity\n",
    "def equal_opportunity(g0_pred, g1_pred, g0_labels, g1_labels):\n",
    "    g0_tpr = np.sum((g0_pred==1) & (g0_labels==1)) / np.sum(g0_labels==1)\n",
    "    g1_tpr = np.sum((g1_pred==1) & (g1_labels==1)) / np.sum(g1_labels==1)\n",
    "    eo = np.abs(g0_tpr - g1_tpr)\n",
    "    return eo\n",
    "\n",
    "\n",
    "dp = demographic_parity(g0_pred, g1_pred)\n",
    "ap = accuracy_parity(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "eod = equalized_odds(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "eo = equal_opportunity(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "\n",
    "print(f'Demographic Parity: {dp:.4f}')\n",
    "print(f'Accuracy Parity: {ap:.4f}')\n",
    "print(f'Equalized Odds: {eod:.4f}')\n",
    "print(f'Equal Opportunity: {eo:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Mitigate Unfairness Using Demographic Parity Loss\n",
    "Add a demographic parity loss regularization to the original loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity_loss(y_pred, sensitive_attr):\n",
    "    \"\"\"\n",
    "    Calculate the demographic parity loss as the difference between\n",
    "    the mean predicted positive rates for different sensitive groups.\n",
    "    \"\"\"\n",
    "    # Group 0 and Group 1 masks\n",
    "    group_0_mask = (sensitive_attr == 0)\n",
    "    group_1_mask = (sensitive_attr == 1)\n",
    "    \n",
    "    group_0_rate = y_pred[group_0_mask].float().mean()\n",
    "    group_1_rate = y_pred[group_1_mask].float().mean()\n",
    "    \n",
    "    dp_loss = torch.abs(group_0_rate - group_1_rate)\n",
    "    return dp_loss\n",
    "\n",
    "# Training with regularization\n",
    "def training_with_dp_regularization(model, criterion, optimizer, train_loader, num_epochs=10, dp_weight=0.1):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels, sensitive_attr, _ in train_loader:\n",
    "            images, labels, sensitive_attr = images.to(device), labels.to(device), sensitive_attr.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss_ce = criterion(outputs, labels)\n",
    "\n",
    "            # Demographic Parity loss   \n",
    "            with torch.no_grad():\n",
    "                _, y_pred = torch.max(outputs.data, 1)\n",
    "                dp_loss = demographic_parity_loss(y_pred, sensitive_attr)\n",
    "            \n",
    "            loss = loss_ce + dp_loss * dp_weight\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4441\n",
      "Epoch [2/10], Loss: 0.1664\n",
      "Epoch [3/10], Loss: 0.2355\n",
      "Epoch [4/10], Loss: 0.0899\n",
      "Epoch [5/10], Loss: 0.0579\n",
      "Epoch [6/10], Loss: 0.4091\n",
      "Epoch [7/10], Loss: 0.3374\n",
      "Epoch [8/10], Loss: 0.0467\n",
      "Epoch [9/10], Loss: 0.2305\n",
      "Epoch [10/10], Loss: 0.1346\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, len(df['label'].unique()))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Use the resampled dataloader to train the model\n",
    "model = training_with_dp_regularization(model, criterion, optimizer, train_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.00%\n",
      "AUC: 0.9620\n",
      "Demographic Parity: 0.0340\n",
      "Accuracy Parity: 0.0260\n",
      "Equalized Odds: 0.0527\n",
      "Equal Opportunity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions, probs, labels, sensitive_attrs = testing(model, test_loader)\n",
    "\n",
    "# Classification performance\n",
    "auc = roc_auc_score(labels, probs)\n",
    "print(f'AUC: {auc:.4f}')\n",
    "\n",
    "# Fairness performance\n",
    "g0_idx = np.where(np.array(sensitive_attrs) == 0)[0]\n",
    "g1_idx = np.where(np.array(sensitive_attrs) == 1)[0]\n",
    "g0_pred = np.array(predictions)[g0_idx]\n",
    "g1_pred = np.array(predictions)[g1_idx]\n",
    "g0_labels = np.array(labels)[g0_idx]\n",
    "g1_labels = np.array(labels)[g1_idx]\n",
    "\n",
    "dp = demographic_parity(g0_pred, g1_pred)\n",
    "ap = accuracy_parity(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "eod = equalized_odds(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "eo = equal_opportunity(g0_pred, g1_pred, g0_labels, g1_labels)\n",
    "\n",
    "print(f'Demographic Parity: {dp:.4f}')\n",
    "print(f'Accuracy Parity: {ap:.4f}')\n",
    "print(f'Equalized Odds: {eod:.4f}')\n",
    "print(f'Equal Opportunity: {eo:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustworthy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
