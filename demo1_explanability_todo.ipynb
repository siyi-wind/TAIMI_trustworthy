{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability and Explainability | Grad-CAM\n",
    "\n",
    "This tutorial demonstrates how to use the **gradient-weighted class activation mapping (Grad-CAM)** [1] to visualize the CNN's saliency map for the skin lesion classification task on the [ISIC 2019](https://challenge.isic-archive.com/data/#2019) dataset. \n",
    "\n",
    "<!-- Use this command to show the figure if you are offline. -->\n",
    "<!-- ![Demo Figure](Util/demo1_1.jpg) -->\n",
    "\n",
    "<img src=\"https://github.com/siyi-wind/TAIMI_trustworthy/raw/main/Util/demo1_1.jpg\" alt=\"Alt text\" width=\"500\">\n",
    "\n",
    "Grad-CAM uses the gradients of any target concept flowing into the final convolutional layer to produce a coarse localization map.\n",
    "\n",
    "In this tutorial, we will cover the following topics\n",
    "\n",
    "- Load a pre-trained CNN\n",
    "\n",
    "- Forward pass a skin image to get the predicted class\n",
    "\n",
    "- Grad-CAM\n",
    "\n",
    "    -  Define Grad-CAM\n",
    "\n",
    "    - Apply Grad-CAM to generate a saliency map\n",
    "\n",
    "    - Visualize Grad-CAM\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note**: To use Google Colab's GPU, click 'Runtime' --> 'Change runtime type' -->  'T4 GPU'\n",
    "\n",
    "[1] Selvaraju, Ramprasaath R., et al. \"Grad-CAM: Visual explanations from deep networks via gradient-based localization.\" Proceedings of the IEEE international conference on computer vision. 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "To run the code on your own computer, please first install [Miniconda](https://docs.anaconda.com/miniconda/install/) and then run the following command to create a virtual environment and install the required packages. \n",
    "```python\n",
    "conda env create --file trustworthy_env.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: If you use Google Colab, uncomment the following code\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# # Change to the path of the tutorial\n",
    "# import os\n",
    "# path = './gdrive/MyDrive/Code/ic/TAIMI_trustworthy' \n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load a Pretrained Model and an Input Image \n",
    "Here we utilize a ResNet-18 [1] that has been pre-trained on skin images.\n",
    "\n",
    "[1] He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load(\"Checkpoint/ISIC2019_model.pth\", weights_only=True))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path)\n",
    "    tensor = preprocess(image).unsqueeze(0)\n",
    "    return tensor, image\n",
    "\n",
    "image_path = \"Data/ISIC2019/images/ISIC_0035900.jpg\"  # Replace with your image path\n",
    "input_tensor, original_image = load_and_preprocess_image(image_path)\n",
    "\n",
    "# Visualize the original image\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(original_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Forward Pass and Get Prediction\n",
    "Forward pass the image through our model to get a classification prediction. The ground-truth label for the ISIC_0035900 image is 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 1\n"
     ]
    }
   ],
   "source": [
    "# Forward pass through the model\n",
    "model.eval()\n",
    "output = model(input_tensor)\n",
    "output = F.softmax(output, dim=1)\n",
    "predicted_class = torch.argmax(output, dim=1).item()\n",
    "print(f\"Predicted class index: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define Grad-CAM\n",
    "\n",
    "<!-- Use this command to show the figure if you are offline. -->\n",
    "<!-- ![Demo Figure](Util/demo1_2.jpg) -->\n",
    "\n",
    "<img src=\"https://github.com/siyi-wind/TAIMI_trustworthy/raw/main/Util/demo1_2.jpg\" alt=\"Alt text\" width=\"600\">\n",
    "\n",
    "To obtain the class-discriminative localization map Grad-CAM $L^c_{Grad-CAM}$ for any class $c$, we need to\n",
    "\n",
    "1. Calculate the neuron importance weights $\\delta_k^c$ of $k$-th feature map $A^k$\n",
    "$$\n",
    "\\delta_k^c = \\overset{\\text{global average pooling}}{\\overbrace{\\frac{1}{Z}\\sum_i\\sum_j}} \\underset{\\text{gradients via back propagation}}{\\underbrace{\\frac{\\partial y^c}{\\partial A^k_{ij}}}} \\tag{1}\n",
    "$$\n",
    "\n",
    "2. Perform a weighted combination of forward activation maps, and follow it by a ReLU\n",
    "$$\n",
    "L^c_{Grad-CAM} = \\operatorname{ReLU} \\underset{\\text{linear combination}}{\\underbrace{(\\sum_k \\delta^c_k A^k)}} \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    # Initialize the GradCAM class\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        self.hook_layers()\n",
    "\n",
    "    # Register hooks to record the gradients and activations\n",
    "    def hook_layers(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    # Generate the Grad-CAM\n",
    "    def generate(self, input_tensor, target_class):\n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        target = output[0, target_class]\n",
    "        target.backward()\n",
    "\n",
    "        # Compute Grad-CAM\n",
    "        # Eq (1)\n",
    "        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)\n",
    "        # TODO: Implement the Eq (2)\n",
    "        cam = 0.0\n",
    "\n",
    "        # Normalize the CAM\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        return cam.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Apply Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target layer and initialize Grad-CAM\n",
    "target_layer = model.layer4[-1].conv2  # Example target layer, the final convolutional layer\n",
    "grad_cam = GradCAM(model, target_layer)\n",
    "\n",
    "# Generate Grad-CAM\n",
    "cam = grad_cam.generate(input_tensor, predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_heatmap_on_image(heatmap, original_image, alpha=0.6, colormap=\"viridis\"):\n",
    "    # Resize heatmap to match original image\n",
    "    heatmap = np.uint8(heatmap * 255)\n",
    "    heatmap_resized = Image.fromarray(heatmap).resize(original_image.size, resample=Image.Resampling.BICUBIC)\n",
    "\n",
    "    # Apply colormap\n",
    "    colormap = plt.get_cmap(colormap)\n",
    "    colored_heatmap = colormap(np.array(heatmap_resized) / 255.0)[:, :, :3]  # Remove alpha channel\n",
    "\n",
    "    # Overlay heatmap on the image\n",
    "    overlay = alpha * colored_heatmap + (1 - alpha) * np.array(original_image) / 255\n",
    "    return np.uint8(255 * overlay)\n",
    "\n",
    "\n",
    "# Display the results     \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(original_image)\n",
    "plt.axis('off')\n",
    "\n",
    "overlayed_image = overlay_heatmap_on_image(cam, original_image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Grad-CAM\")\n",
    "plt.imshow(original_image)\n",
    "plt.imshow(overlayed_image, cmap='jet', alpha=0.5)  # Overlay the heatmap\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking\n",
    "\n",
    "1. Try to visualize the saliency map of different layers.  How does this choice affect the heatmap quality?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustworthy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
